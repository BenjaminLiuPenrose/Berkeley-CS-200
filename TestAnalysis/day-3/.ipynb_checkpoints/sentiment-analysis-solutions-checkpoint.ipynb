{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis\n",
    "\n",
    "### What is sentiment analysis?\n",
    "\n",
    "In this notebook, we're going to perform [sentiment analysis](https://en.wikipedia.org/wiki/Sentiment_analysis) on a dataset of tweets about US airlines. Sentiment analysis is the task of extracting [affective states][1] from text. Sentiment analysis is most ofen used to answer questions like:\n",
    "\n",
    "[1]: https://en.wikipedia.org/wiki/Affect_(psychology)\n",
    "\n",
    "- _what do our customers think of us?_\n",
    "- _do our users like the look of our product?_\n",
    "- _what aspects of our service are users dissatisfied with?_\n",
    "\n",
    "### Sentiment analysis as supervised classification\n",
    "\n",
    "We're going to treat sentiment analysis as a typical text classification problem. Text classification is just like other instances of classification in data science. We use the term \"text classification\" when the features come from natural language data. What makes text classification interestingly different from other instances of classification is the way we extract numerical features from text. \n",
    "\n",
    "In addition, we are going to perform sentiment analysis as a _supervised_ method: unlike _unsupervised_ LDA topic modeling from day 2 where the topics were latent, _supervised_ classification relies on a train set with known labels. In today's example labels are already provided. In real life, labelling a train set would require some _ex ante_ human work.\n",
    "\n",
    "### Dataset\n",
    "\n",
    "The dataset was collected by [Crowdflower](https://www.crowdflower.com/), which they then made public through [Kaggle](https://www.kaggle.com/crowdflower/twitter-airline-sentiment) and is now in your \"data\" directory. Note that this is a nice clean dataset; not the norm in real-life data science! But it's perfect for our purpose: concentrate on understanding what text classification is and how to do it.\n",
    "\n",
    "### Topics\n",
    "\n",
    "Here's what we'll cover in our hour. Like any data science task, we'll first do some EDA to understand what data we've got. Then, like always, we'll have to preprocess our data. Because this is text data, it'll be a little different from preprocessing other types of data. Next we'll perform our sentiment classification. Finally, we'll interpret the results of the classifier in terms of our big question.\n",
    "\n",
    "We'll cover:\n",
    "\n",
    "[EDA](#eda)<br>\n",
    "\n",
    "[Preprocess](#preprocess)<br>\n",
    "\n",
    "[Classification](#classification)<br>\n",
    "\n",
    "[Interpret](#interpret)<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA <a id='eda'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'data'\n",
    "fname = os.path.join(DATA_DIR, 'tweets.csv')\n",
    "df = pd.read_csv(fname)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which airlines are tweeted about and how many of each in this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(df['airline'], order=df['airline'].value_counts().index);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "\n",
    "- How many tweets are in the dataset?\n",
    "- How many tweets are positive, neutral and negative?\n",
    "- What **proportion** of tweets are positive, neutral and negative?\n",
    "- Visualize these last two questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Length is\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['airline_sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['airline_sentiment'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(df['airline_sentiment'], order=['positive', 'neutral', 'negative']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['airline_sentiment'].value_counts(normalize=True, ascending=True).plot(kind='bar', rot=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra challenge\n",
    "\n",
    "- When did the tweets come from?\n",
    "- Who gets more retweets: positive, negative or neutral tweets?\n",
    "- What are the reasons why people tweet negatively? Show distribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**All the tweets in this dataset came from the third week of February 2015.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.to_datetime(df['tweet_created'])\n",
    "print(\"Year:\\n\")\n",
    "print(dates.dt.year.value_counts())\n",
    "print(\"Month:\\n\")\n",
    "print(dates.dt.month.value_counts())\n",
    "print(\"Day:\\n\")\n",
    "print(dates.dt.day.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't see any interesting evidence of tweets of different classes getting more or less retweets. The vast majority of tweets from all three classes get no retweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('airline_sentiment')['retweet_count'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(df['negativereason'], order=df['negativereason'].value_counts().index)\n",
    "plt.xticks(rotation=90); #add this line to rotate X labels and be able to read them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess  <a id='preprocess'></a>\n",
    "\n",
    "### Regular expressions\n",
    "\n",
    "Regular expressions are like advanced find-and-replace. They allow us to specify complicated patterns in text data and find all the matches. They are very useful in text processing. You can learn more about them [here](https://github.com/geoffbacon/regular-expressions-in-python).\n",
    "\n",
    "We can use regular expressions to find hashtags and user mentions in a tweet. We first write the pattern we're looking for as a (raw) string, using regular expression's special syntax. The `twitter_handle_pattern` says \"find me a @ sign immediately followed by one or more upper or lower case letters, digits or underscore\". The `hashtag_pattern` is a little more complicated; it says \"find me exactly one ＃ or #, immediately followed by one or more upper or lower case letters, digits or underscore, but only if it's at the beginning of a line or immediately after a whitespace character\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "twitter_handle_pattern = r'@(\\w+)'\n",
    "hashtag_pattern = r'(?:^|\\s)[＃#]{1}(\\w+)'\n",
    "url_pattern = r'https?:\\/\\/.*.com'\n",
    "example_tweet = \"lol @justinbeiber and @BillGates are like soo #yesterday #amiright saw it on https://twitter.com #yolo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(twitter_handle_pattern, example_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(hashtag_pattern, example_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(url_pattern, example_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pandas` has great in-built support for operating with regular expressions on columns. We can `extract` all user mentions from a column of text like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'].str.extract(twitter_handle_pattern).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And find all the hashtags like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'].str.extract(hashtag_pattern).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "\n",
    "Often in preprocessing text data, we don't care about the exact hashtag/user/URL that someone used (although sometimes we do!). Your job is to replace all the hashtags with `'HASHTAG'`, the user mentions with `'USER'` and URLs with `'URL'`. To do this, you'll use the `replace` string method of the `text` column. The result of this will be a series, which you should add to `df` as a column called `clean_text`. **See the docs [here](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.str.replace.html) for more information on the method.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text'] = (df['text']\n",
    "                    .str.replace(hashtag_pattern, 'HASHTAG')\n",
    "                    .str.replace(twitter_handle_pattern, 'USER')\n",
    "                    .str.replace(url_pattern, 'URL')\n",
    "                              )\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "## Logistic regression with binary class\n",
    "\n",
    "To understand the theoretical gist of our classification task, let's first focus on a binary 'positive vs negative' classifier. We are going to do so by restricting the analysis to the non-neutral tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bin=df[df['airline_sentiment']!='neutral']\n",
    "len(df_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of words and DTM\n",
    "\n",
    "First, we need to turn the text into numbers for our classifier. We're going to use a \"bag of words\" as our features. A bag of words is just like a frequency count of all the words that appear in a tweet. It's called a bag because we ignore the order of the words; we just care about what words are in the tweet. To do this, we can use `scikit-learn`'s `CountVectorizer` to build up the document-term matrix (see notebook from day 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "countvectorizer = CountVectorizer(max_features=5000, binary=True)\n",
    "X = countvectorizer.fit_transform(df_bin['clean_text'])\n",
    "features = X.toarray()\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = df_bin['airline_sentiment'].values\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into train/test datasets\n",
    "\n",
    "We don't want to train our classifier on the same dataset that we test it on, so let's split it into training and test sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, response, test_size=0.2)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit a logistic regression model\n",
    "\n",
    "OK, so now that we've turned our data into numbers, we're ready to feed it into a classifier. More specifically, we are going to fit a logistic regression model where the probability of being positive ($y=1$) is described by a sigmoid function of the form:\n",
    "$f(X)=P(y=1|X)=\\frac{exp(-X'\\theta)}{1+exp(-X'\\theta)}$. Once $\\theta$ - a vector of word _weights_ or _loadings_ - is estimated we can get predict outcomes $\\hat{f}$ conditional on observed word count $X$. If $\\hat{f}>0.5$ then the observation is classified as positive. \n",
    "\n",
    "To those interested in the technicalities, the model is estimated through penalized Maximum Likelihood with cross-validation. (It's always good to know and understand at a high-level what your code is actually doing...)  \n",
    "\n",
    "We're not going to concentrate too much on the code below, but here's the big picture. In the `fit_model` function defined below, we're going to use the logitistic regression classifier described abover to take in the numerical representation of the tweets and spit out whether it's positive or negative. Then we'll use `test_model` to test the model's performance against our test data and print out some results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_logistic_regression(X_train, y_train):\n",
    "    model = LogisticRegressionCV(Cs=5, penalty='l1', cv=3, solver='liblinear', refit=True)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "def conmat(model, X_test, y_test):\n",
    "    \"\"\"Wrapper for sklearn's confusion matrix.\"\"\"\n",
    "    labels = model.classes_\n",
    "    y_pred = model.predict(X_test)\n",
    "    c = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(c, annot=True, fmt='d', \n",
    "                xticklabels=labels, \n",
    "                yticklabels=labels, \n",
    "                cmap=\"YlGnBu\", cbar=False)\n",
    "    plt.ylabel('Ground truth')\n",
    "    plt.xlabel('Prediction')\n",
    "    \n",
    "def test_model(model, X_train, y_train):\n",
    "    conmat(model, X_test, y_test)\n",
    "    print('Accuracy: ', model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = fit_logistic_regression(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(lr, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1\n",
    "\n",
    "Fit a _multinomial_ logit model to classify tweets between positive, negative AND neutral. Hint: the functions defined above do not need to change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = countvectorizer.fit_transform(df['clean_text'])\n",
    "features = X.toarray()\n",
    "response = df['airline_sentiment'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, response, test_size=0.2)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = fit_logistic_regression(X_train, y_train)\n",
    "test_model(lr, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2\n",
    "\n",
    "Use the `RandomForestClassifier` imported above to construc a `fit_random_forest` function and train a random forest classifier on the training set. Test the model on the test set. Which performs better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_random_forest(X_train, y_train):\n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf = fit_random_forest(X_train, y_train)\n",
    "test_model(rf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More validation\n",
    "\n",
    "We are going to use the `test_tweet` function below to test your classifier's performance on our own tweets. We can do it using both LR or RF classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_tweets(tweets):\n",
    "    tweets = [re.sub(hashtag_pattern, 'HASHTAG', t) for t in tweets]\n",
    "    tweets = [re.sub(twitter_handle_pattern, 'USER', t) for t in tweets]\n",
    "    return [re.sub(url_pattern, 'URL', t) for t in tweets]\n",
    "\n",
    "def test_tweets(tweets, model):\n",
    "    tweets = clean_tweets(tweets)\n",
    "    features = countvectorizer.transform(tweets)\n",
    "    predictions = model.predict(features)\n",
    "    return list(zip(tweets, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tweets = [example_tweet,\n",
    "            'omg I am never flying on United again',\n",
    "            'I love @VirginAmerica so much #friendlystaff',\n",
    "            'food on Air France is great!']\n",
    "\n",
    "test_tweets(my_tweets, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpret <a id='interpret'></a>\n",
    "\n",
    "Now we can interpret the classifier by the features that it found important. Let's do it for our preferred logistic regression classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important = pd.DataFrame(lr.coef_).T\n",
    "important.columns = lr.classes_\n",
    "important['word'] = countvectorizer.get_feature_names()\n",
    "important.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important.sort_values(by='negative', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important.sort_values(by='positive', ascending=False).head(10)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
